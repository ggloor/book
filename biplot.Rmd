# Exploring compositional data: the compositional biplot

There are three main data analysis issues that must be acknowledged.

First, the nature of these data are misunderstood. As outlined above, the number of counts observed  per OTU are determined entirely by the capacity of the instrument and provide no information about the number of molecules in the input sample. Recall that both bacterial growth, and PCR are doubling processes and not linear processes, and so would be better modelled as log$_2$ differences.

Understanding that we are dealing with fold-change data is an explicit acknowledgement that the data do not map to normal Euclidian space where differences are linear.  Commonly used statistical tests expect linear differences between values and so are compromised to some degree, often catastrophically[@Aitchison:1986,vandenBoogaart2008320] Therefore, the often-used approaches of converting the OTU count values to proportions or percentages and conducting statistical tests on those values, or of using data reduction strategies such as Principle Component Analysis on the  values are inappropriate because the differences between values are not linear. An alternative approach is to convert the OTU counts to ratios[@Aitchison:1986;@aitchison:2005;@Pawlowsky-Glahn:2006;@pawlowsky2011compositional] which makes the differences between the ratios of values linear, and so allows the use of common statistical tests.

However the user must interpret the output as ratios between feature abundances rather than absolute differences[@pawlowsky2011compositional] This approach is described below.

Second, high throughput sequencing (HTS) data represent samples of an unknown underlying large number of molecules. Thus, there is a large and unappreciated  error of estimation that is problematic when dealing with these data[@fernandes:2013] The high error of estimation often results in false positive identification of differences, in fact, the statistical result can often be explained entirely by sampling variation.  This error is not captured by rarefaction or even acknowledged by other normalization methods and should be estimated and accounted for when deciding what is a significant difference.

Third, 16S rRNA gene sequencing surveys, and similar experiments, contain many variables in each sample. Thus, any analysis that attempts to characterize the individual differences between groups must correct for the many hypotheses that are being tested. This step is often ignored, even in work published in very high profile journals subject to rigorous peer review.

The purpose of these notes is to show  why HTS data for 16S rRNA gene sequencing, and any similar experiments such as RNA-seq, should be treated as ratio data and that it is possible to do so simply. We show that this approach accurately recapitulates the shape of the data for both constrained and unconstrained datasets. We show that converting the data to ratios can accurately model the very high variability at the low count margins, and that rarefaction under-estimates this variability. We use an example from the literature to show how ignoring these factors leads to improper conclusions.
