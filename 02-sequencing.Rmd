# The nature of sequencing data {#sequencing}

The human microbiome project has initiated the large-scale culture-independent analysis of microbial communities, and transcriptome analysis has led to the study of the transcriptional response to many different disease and ecological states.

However, many studies fail to replicate earlier studies even when the same technologies and strategies are used. As just one example, a multitude of studies have examined the link between autism and the human gut microbiota. These have variously implicated x,y,...,and z microbe as being linked to the condition. In a recent high-profile paper by Hsiao et al. [-@Hsiao:2013], \emph{Bacillus fragilis} was suggested to restore the gut microbiome of a mouse autism model from 'autistic-like' to 'normal'. Examination of the dataset shows that the conclusion was likely due to chance alone [@gloor2016s;@Gloor:2016cjm]. While the autism dataset serves as a facile example, the literature are replete with other examples.

## DNA sequencing describes a random sample of the environment

All high throughput gene sequencing datasets share a common origin and it is important to understand the source of the data, and the standard workflow. In the first step, an arbitrarily large population of DNA molecules is randomly sampled from an environment. The random sampling can be direct, in the case of genomics or metagenomics DNA is made directly from the sample. Sampling can be indiredt in the case of RNA-seq where RNA molecules are sampled after they have been converted to DNA via reverse transcription. Regardless, the DNA molecules are typically fragmented. Sampling can also be indirect in the case of tag-sequencing or single cell sequencing. In tag-sequencing, most typically applied to 16S rRNA gene sequencing, a small defined region is amplified by the PCR. In single cell sequencing the molecules from a single cell are fragmented and amplified.

In the second step, an aliquot of the population of DNA fragments are used to make a library by attaching standard sequences that permit the DNA fragments to be bound to the solid phase sequencing chip particular to a particular platform.

In the third step  a sample of the library is loaded onto a sequencing platform. It is important to understand that all sequencing platforms in widespread use contain a fixed number of locations to which the  DNA fragments can bind.

This standardized workflow can be thought of as three random samples from an urn containing a random assortment of DNA fragments. The first random sample is the sample from the environment itself that is used to make the DNA: what is swabbed, and how much is collected relative to the environment. Depending on the environment, the subset of molecules sampled can be a large and complete sample or a small, incomplete and unrepresentative sample. The second random sample is the subset of DNA fragments that are input into the library preparation reaction. Here, the number of fragments available depends on the initial amount of the DNA, the mean fragment size and the requirements of the library preparation protocol. However, all library preparation protocols required more DNA fragments than can be loaded onto the instrument, an example calculation is given below. The third random sample comprise the subset of DNA fragments from the library that are actually sequenced on the machine.

### Instrument capacity

The Ion Torrent and Ion Proton systems have a chip with a predetermined number of pores on the sequencing chip (10 of thousands to 10s of millions, depending on the chip) that can accept a library fragment. No signal is returned from an empty pore, and the signal is rejected if a pore contains two or more different fragments. Sequencing is successful only when the pore is occupied by a single fragment from the library.

The Illumina sequencing instruments attach the DNA fragments to a glass slide and then each fragment is amplified into millions of identical fragments called clusters, which appear as randomly distributed spots under a microscope. Each different Illumina instrument accommodates a characteristic maximum number of clusters, and if two or more clusters  overlap they are rejected by the software.

Thus, regardless of instrument, the technician must apply a precise number of DNA molecules that maximizes the number of fragments on the sequencing instrument without overloading it. It should be obvious that loading a DNA sequencer is akin to filling the squares on a checkerboard where the goal is to have as many checkers as possible, without overlapping the pieces.


### Example calculation of fragment number

The number of fragments after sequencing is determined by the instrument; an Ilumina MiSeq delivers $\sim 20$M fragments whereas an Illumina NextSeq delivers $\sim 400$M and an Illumina HiSeq can deliver $\sim 250$M reads per lane on each of 8 lanes. The commonly used Nextera DNA library kit is optimized to require 50 ng of DNA per sample. Thus, the number of fragments of DNA (or RNA) molecules in the underlying environment, in general,  vastly outnumbers the number of sequence fragments from which the library is made, and the number of fragments in the library  in turn outnumbers the number of fragments from which sequencing data are ultimately derived. We can do a simple back of the envelope calculation for an example metagenomics sequencing run to show this.

Assume that we have a mixture of bacterial species with a mean genome size of 4 Mb. One mole of genomes would have a mass of $2.64 \times 10^9$ grams. A typical bacterial density for a metagenome would be on the order of at least $10^7$ bacteria per ml of sample, so if we take a 1 ml sample, this is $10^7$ genomes, which corresponds to about 44 ng of DNA.

If the DNA concentration after isolation is 1 ng$/ \mu$l, and one $\mu$l of DNA is taken, this corresponds to ($1\times 10^{-9} \mathrm{\ g}) / (2.64 \times 10^9\ \mathrm{g/mole})  \times (6.02 \times 10^{23} \mathrm{\ genomes/mole}) = 228,000$ genomes. The Illumina Nextera XT kit can be used to make a library with this amount of DNA. Recall that the the DNA is fragmented, typically into 500 bp or smaller sizes. Using a fragment size of 500 bp, this corresponds to approximately $1.8 \times 10^9$ DNA fragments.

In the scenario where a single sample is prepared and run only 1% of DNA fragments in the library will be sequenced on the Illumina MiSeq, and only 22% of the DNA fragmments will be sequenced on the Illumina NextSeq. DNA sequencing rarely involves a single sample, but instead samples are 'multiplexed' on the sequencing run by mixing two or more libraries together. When this occurs the samples have a unique tag, or barcode, attached so that the samples can be uniquely identified post sequencing [@Parameswaran:2007aa;@Andersson:2008;@Gloor:2010]. Barcodes can be added by ligation or by incorporation into PCR primers that are used to amplify the library.  Obviously, increasing the number of samples through multiplexing will result in an even smaller proportion of the fragments in each  library being sequenced.


## DNA sequencing is not counting

From the above, it should be clear that DNA sequencing is not a counting operation but is instead a random sampling operation from a large pool, akin to sampling different colored balls from an urn containing more balls than are sampled. A counting operation always allows the addition of 'one more observation'. In the context of DNA  sequencing this would equate to loading the samples onto an Illumina MiSeq chip to the optimal fragment density and then adding in 'one more fragment' repeatedly until the number of fragments loaded exceed the capacity of the chip. The sequencing reaction will fail when the number of frangments exceeds the chip capacity. Stated bluntly, one cannot purchase an Illumina MiSeq run and expect to receive data equivalent to an Illumina NextSeq or HiSeq run. This self-evident fact is completely overlooked in the literature.

If the number of DNA fragments sequenced is has an arbitrary upper bound determined by the machine, and the number of fragments in the library is always larger than the machine capacity, then it should be obvious that the number of fragments sequenced can contain no information about the \emph{number} of fragments in the library pool, nor can the number of fragments contain information about the \emph{number}  of molecules in the original DNA sample from the environment. The univariate logical equivalent is to only know the percentage that a suit is marked down to, without knowing the original price. The multivariate intuition is that we cannot know the number of balls of different colour in the urn, we can only infer their proportions.

Therefore, the only information available is the \emph{relative} proportion of individual fragments in the library, which is assumed to approximate the proportion of fragments in the  DNA sample from the environment.We will revisit this issue when we discuss normalizations in common use.

## Random processes in sequencing

The random sampling process in DNA sequencing has at least three overlapping stochastic processes; environmental sampling, fragment sampling and multiplex sampling.

Sampling from the environment is random since the investigator never collects all the DNA samples from an environment, but rather collects a small aliquot from a specific time or place in the environment. Only the DNA molecules actually collected are used to make the DNA library, and these molecules are assumed to be representative of the environment. Note that this assumption may not always be true. For example, it has been observed that different microbial compositions are observed when collecting stool samples if a sample is taken from the interior or exterior of the stool [@Gorzelak:2015aa].

Fragment sampling occurs because as noted above the fragments actually sequenced are a random sample of the fragments that are in the sequencing library. There are always more fragments in the library than can be accommodated on the instrument, and there are almost always more molecules in the environment than can be accommodated in the library. The sole exception to this rule would be when sequencing is used to investigate low biomass environments---however in this case the library protocols always have an amplification step that increases the number of fragments above the number that can be accommodated on the instrument. The fragment sampling occurs by a multivariate Poisson process [@fernandes:2013].

Two or more independent libraries are mixed together into a multiplex library, and this adds a third level of randomness into the process. The number of fragments in each library is one of the strongest influences on the apparent information in the sample [@Horner-Devine:2004aa;@Weiss:2017aa]. The number of fragments observed post sequencing is termed the `library size' or the '`'depth of coverage'.  In other words, the number of fragments identified in a sample post sequencing is a confounding variable.

The apparent solution to the sequencing depth problem is to normalize the read count values across samples in some way. One method of normalization to is by subsampling, often termed rarefaction, as this is observed to reduce the influence of sequencing depth on variation in $\alpha$ and $\beta$ diversity metrics [@Horner-Devine:2004aa;@Weiss:2017aa]. Another is to convert the data to proportions or percentages; these latter values are widely spoken of in the literature as `relative abundances'. Subsampling is frequently used to estimate the associated sampling error. Some groups have begun advocating the use of  normalization methods prevalent in the RNA-seq field[@McMurdie:2014a] but still treat the data as point estimates of the true abundance. There are many other normalizations that are used in the ecological and high throughput sequencing literature and the purpose and effect of these on simulated data are explored in the section on Data Transformations.

## Sequencing post processing

After sequencing fragments are grouped in some way

### Mapping

Fragments generated from metagenomic or RNA-seq experiments are aligned to reference sequences corresponding to genes, transcripts or genetic intervals (generically genes). The total number of fragments mapping to a given gene is said to be the read count for that gene and the read count for all genes in a system ranges from 0 (no fragments align to that gene) to the total number of fragments in the sample. The output from these types of experiments is a table of read counts per gene per sample.

Expand this to outline methods

### OTU generation

Fragments generated from tag-sequencing are often merged into operational taxonomic units (OTUs) at some predefined percent identity, or tabulated by the number of identical fragments observed (ASUs). The output from these types of experiments is a table of counts per OTU per sample.
